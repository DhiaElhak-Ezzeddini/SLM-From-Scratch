{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6252a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLM_Architecture import GPTConfig,GPTModel\n",
    "import torch \n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a73cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPTConfig(\n",
    "    vocab_size=50257,\n",
    "    block_size=128,\n",
    "    n_layer=6,\n",
    "    n_head=6,\n",
    "    n_embed=384,\n",
    "    dropout=0.1,\n",
    "    bias=True\n",
    "\n",
    ")\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "trained_model = GPTModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541b5598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 384)\n",
       "    (wpe): Embedding(128, 384)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Transformer_Block(\n",
       "        (ln1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (c_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (residual_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2546c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHIA\\AppData\\Local\\Temp\\ipykernel_17060\\3656142735.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  trained_model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "trained_model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90329ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a pumpkin. It was very perfect for him. Daddy's why theens was sad and scared. \n",
      "\n",
      "One day, the cushion got stuck in and it fell into a tree. It was a girl who was very sad. She looked at the angel and started pulling it off the branches of the tree. \n",
      "\n",
      "Okay Mommy helped away the girl gently close the label. Iners it was a bit truly raise that looked even a bit so incredible. It was the man from the tree in his pocket and it made a smile.\n",
      "\n",
      "The girl was surprised, but then dad gave her a big hug and they started to joyful the photo. It was so happy to share and cost it a lot of fun!\n",
      "\n",
      "And they lived happily ever after that hat.Once upon a time, there was a little girl named Julie. She was three years old but she was very gifted. She loved to play outside and chew her toys with her blocks. One day, Maddies was hungry and\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Once upon a time there was a pumpkin.\"\n",
    "context = (torch.tensor(tokenizer.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
    "y = trained_model.generate(context, 200)\n",
    "print(tokenizer.decode(y.squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc042318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little car named Beep. Swuck off, and aliens. One day, Fluffy was playing in the park when he saw a big greenite on the edge of the field.\n",
      "\n",
      "Ew went towards the bottom of the cliff and swam for a cat. Punes were very soft and happy. Fluffy knew it was her sack.\n",
      "\n",
      "When she opened, far and came back to her, Fluffyune scooter had flown down on the grass and saw Floppy badly. Fllets got stuck in the grass. But Fluffy felt sad, but she should be humble with her.\n",
      "\n",
      "Fluffy thought, \" Innovation, I know. Let's reverse our rules and get us and watch you speed. We can both finish reversing the highest breeze so far away andnamching Sara in her eyes. Now it has so much fun andooter is so kind. One day, Pinkty was playing a game when he saw a little girl, it was lost from a broken penny in the shop\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Once upon a time, there was a little car named Beep\"\n",
    "context = (torch.tensor(tokenizer.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
    "y = trained_model.generate(context, 200)\n",
    "print(tokenizer.decode(y.squeeze().tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
